{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     /Users/dylanedwards/nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dylanedwards/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/dylanedwards/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('opinion_lexicon')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "punctuation = string.punctuation\n",
    "positive_dict = set(opinion_lexicon.positive())\n",
    "negative_dict = set(opinion_lexicon.negative())\n",
    "positive_dict_stemmed = [PorterStemmer().stem(word) for word in positive_dict]\n",
    "negative_dict_stemmed = [PorterStemmer().stem(word) for word in negative_dict]\n",
    "\n",
    "contractions = {\n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}\n",
    "\n",
    "def get_files_from_dir(directory):\n",
    "    return [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "\n",
    "def process_string_sentence(text):\n",
    "        englishStopwords = stopwords.words(\"english\")  # non-neccesary words\n",
    "        text = text.lower()  # case folding\n",
    "        # remove punctuation\n",
    "        text = \"\".join([char for char in text if char not in punctuation])\n",
    "        words = word_tokenize(text)\n",
    "        removed = [word for word in words if word not in englishStopwords]\n",
    "        stemmed = [PorterStemmer().stem(word) for word in removed]\n",
    "        stemmed_sentence = \" \".join(stemmed)\n",
    "        return stemmed_sentence\n",
    "\n",
    "def process_string(text):\n",
    "        englishStopwords = stopwords.words(\"english\")  # non-neccesary words\n",
    "        text = text.lower()  # case folding\n",
    "        # remove punctuation\n",
    "        text = \"\".join([char for char in text if char not in punctuation])\n",
    "        words = word_tokenize(text)\n",
    "        removed = [word for word in words if word not in englishStopwords]\n",
    "        return [\", \".join(removed)]\n",
    "\n",
    "\n",
    "def tokenize_files(files, dir):\n",
    "        cleaned_positive_files = []\n",
    "        for file in files:\n",
    "            file_path = str.format(\"{}/{}\", dir, file)\n",
    "            with open(file_path) as f:\n",
    "                raw_text = f.read()\n",
    "                cleaned_positive_files.append(process_string(raw_text))\n",
    "        return cleaned_positive_files\n",
    "\n",
    "def is_word_positive(word):\n",
    "        if word in positive_dict or word in positive_dict_stemmed:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "def is_word_negative(word):\n",
    "    if word in negative_dict or word in negative_dict_stemmed:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def get_word_occurrences(tokenized_files):\n",
    "        word_occurrences = {}\n",
    "        word_occurrences[\"positive\"] = 0\n",
    "        word_occurrences[\"negative\"] = 0\n",
    "        total_num_words = 0\n",
    "        for file in tokenized_files:\n",
    "            # calc number exclams\n",
    "            # calc number pos/neg/words\n",
    "            for word in file:\n",
    "                if is_word_positive(word):\n",
    "                    word_occurrences[\"positive\"] += 1\n",
    "                if is_word_negative(word):\n",
    "                    word_occurrences[\"negative\"] += 1\n",
    "                if word not in word_occurrences:\n",
    "                    word_occurrences[word] = 0\n",
    "                word_occurrences[word] += 1\n",
    "                total_num_words += 1\n",
    "        return word_occurrences, total_num_words\n",
    "\n",
    "def get_raw_text_from_files(files: list, dir: str) -> list:\n",
    "    raw_text = []\n",
    "    for file in files:\n",
    "        file_path = str.format(\"{}/{}\", dir, file)\n",
    "        with open(file_path) as f:\n",
    "            file_text_in_lines = f.read()\n",
    "            raw_text.append(file_text_in_lines)\n",
    "    return raw_text\n",
    "\n",
    "def clean_text(text, remove_stopwords = True):\n",
    "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
    "\n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # Replace contractions with their longer forms\n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "\n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text)\n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "\n",
    "    # remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    # Tokenize each word\n",
    "    text =  nltk.WordPunctTokenizer().tokenize(text)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0       [ordered, hp4705, bluetooth, keyboard, sent, t...\n1       [hoping, buy, small, handheld, vacuum, office,...\n2       [bought, 3, vtech, phones, house, since, begin...\n3       [canon, s2, batteries, last, almost, long, che...\n4       [purchased, 10, drives, mistake, flakey, disap...\n                              ...                        \n1995    [received, pretty, quick, sdsdqu, 1024, e10m, ...\n1996    [listed, product, description, pico, works, ip...\n1997    [bought, folks, christmas, took, time, hook, m...\n1998    [purchased, monster, cable, mp, hts, 1000, wit...\n1999    [fabulous, product, store, 700, photos, 8, meg...\nName: Text_Cleaned, Length: 2000, dtype: object"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "neg_data = np.array(get_raw_text_from_files(get_files_from_dir(\"./data/neg\"), \"data/neg\"))\n",
    "pos_data = np.array(get_raw_text_from_files(get_files_from_dir(\"./data/pos\"), \"data/pos\"))\n",
    "allData = np.concatenate((neg_data, pos_data))\n",
    "# making labels for the data, the first\n",
    "neg_labels = np.fromiter([0 for i in range(len(neg_data))], int)  # create negative labels\n",
    "pos_labels = np.fromiter([1 for i in range(len(pos_data))], int)  # create positive labels\n",
    "allLabels = np.concatenate((neg_labels, pos_labels))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Text_Cleaned'] = list(map(clean_text, allData))\n",
    "df['Text_Cleaned']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'ordered': 7011,\n 'hp4705': 4995,\n 'bluetooth': 1519,\n 'keyboard': 5634,\n 'sent': 8838,\n 'two': 10389,\n 'non': 6784,\n 'item': 5508,\n 'send': 8820,\n 'back': 1257,\n 'hope': 4952,\n 'get': 4498,\n 'credit': 2628,\n 'hoping': 4959,\n 'buy': 1740,\n 'small': 9153,\n 'handheld': 4722,\n 'vacuum': 10685,\n 'office': 6922,\n 'computer': 2322,\n 'hardware': 4763,\n 'keyboads': 5633,\n 'air': 798,\n 'inlets': 5292,\n 'however': 4991,\n 'datavac': 2774,\n 'little': 5961,\n 'power': 7584,\n 'even': 3738,\n 'full': 4372,\n 'charge': 1993,\n 'next': 6745,\n 'useless': 10643,\n 'cannot': 1825,\n 'recommend': 8097,\n 'bought': 1593,\n '3': 236,\n 'vtech': 10850,\n 'phones': 7365,\n 'house': 4985,\n 'since': 9049,\n 'begining': 1381,\n 'battery': 1329,\n 'problems': 7699,\n 'really': 8016,\n 'annoying': 950,\n 'make': 6144,\n 'phone': 7361,\n 'call': 1791,\n 'work': 11157,\n 'point': 7508,\n 'time': 10096,\n 'least': 5823,\n 'one': 6957,\n 'constantly': 2422,\n 'reports': 8301,\n 'low': 6056,\n 'message': 6333,\n 'means': 6272,\n 'use': 10636,\n 'course': 2571,\n 'hear': 4817,\n 'ring': 8474,\n 'never': 6730,\n 'room': 8529,\n 'run': 8574,\n 'pick': 7382,\n 'location': 5980,\n 'problem': 7696,\n 'reviewers': 8437,\n 'noted': 6813,\n 'spite': 9347,\n 'fact': 3933,\n 'minimal': 6415,\n 'leave': 5826,\n 'charger': 1995,\n 'beginning': 1383,\n 'used': 10638,\n 'take': 9851,\n 'put': 7857,\n 'quite': 7907,\n 'anymore': 985,\n 'tried': 10296,\n 'support': 9703,\n 'live': 5963,\n 'person': 7338,\n 'number': 6851,\n 'website': 10978,\n 'suggest': 9662,\n 'replacing': 8289,\n 'batteries': 1328,\n 'rechargeable': 8070,\n 'many': 6183,\n 'times': 10098,\n 'supposed': 9709,\n 'new': 6734,\n 'baterries': 1323,\n 'already': 872,\n 'replaced': 8285,\n 'know': 5681,\n 'wont': 11144,\n 'products': 7721,\n 'canon': 1826,\n 's2': 8596,\n 'last': 5766,\n 'almost': 860,\n 'long': 6010,\n 'cheap': 2009,\n 'costco': 2543,\n 'rechargable': 8068,\n 'ones': 6959,\n 'upto': 10618,\n '8': 475,\n 'hours': 4984,\n 'amazon': 896,\n 'correct': 2528,\n 'anyone': 987,\n 'good': 4563,\n 'lasting': 5769,\n '2500': 198,\n 'mah': 6128,\n 'purchased': 7840,\n '10': 15,\n 'drives': 3314,\n 'mistake': 6460,\n 'flakey': 4143,\n 'disappear': 3093,\n 'copying': 2516,\n 'data': 2771,\n 'usb': 10632,\n 'turn': 10366,\n 'drive': 3310,\n 'windows': 11079,\n 'find': 4090,\n 'lacie': 5717,\n 'backup': 1275,\n 'reason': 8024,\n 'large': 5758,\n 'amounts': 911,\n 'fail': 3941,\n 'start': 9431,\n 'copy': 2515,\n 'chunks': 2059,\n 'failed': 3942,\n 'months': 6525,\n 'month': 6522,\n 'mark': 6203,\n 'realize': 8013,\n 'still': 9491,\n 'warranty': 10922,\n '1': 14,\n 'year': 11258,\n '2': 158,\n 'left': 5835,\n 'contacted': 2436,\n 'asking': 1104,\n 'original': 7022,\n 'invoice': 5445,\n 'clearly': 2107,\n 'listed': 5945,\n 'purchase': 7839,\n 'date': 2775,\n 'began': 1378,\n 'ignoring': 5100,\n 'email': 3541,\n 'would': 11182,\n 'honor': 4941,\n 'rma': 8497,\n 'requesting': 8317,\n '5': 341,\n 'responses': 8368,\n 'could': 2553,\n 'come': 2221,\n 'refuse': 8168,\n 'service': 8866,\n 'longer': 6011,\n 'warranties': 10920,\n 'reliable': 8215,\n 'better': 1427,\n 'companies': 2254,\n 'mouse': 6559,\n 'feel': 4032,\n 'scroll': 8737,\n 'smoothly': 9177,\n 'like': 5912,\n 'contrary': 2465,\n 'microsoft': 6370,\n 'says': 8677,\n 'buttons': 1738,\n 'programmable': 7735,\n 'select': 8802,\n 'predefined': 7616,\n 'list': 5944,\n 'chose': 2052,\n 'silver': 9030,\n 'side': 9003,\n 'paste': 7237,\n 'neither': 6711,\n 'works': 11168,\n 'another': 957,\n 'irritation': 5483,\n 'getting': 4501,\n 'popup': 7534,\n 'signal': 9012,\n 'weak': 10966,\n '18': 117,\n 'away': 1236,\n 'yet': 11264,\n 'menu': 6317,\n 'fine': 4093,\n 'got': 4574,\n 'great': 4619,\n 'officedepot': 6923,\n 'half': 4712,\n 'price': 7663,\n 'otherwise': 7034,\n 'return': 8415,\n 'please': 7475,\n 'expect': 3832,\n 'cash': 1891,\n 'promised': 7754,\n 'denied': 2915,\n 'twice': 10385,\n 'second': 8773,\n 'said': 8618,\n 'u': 10403,\n 'p': 7123,\n 'c': 1754,\n 'invalid': 5428,\n 'barcode': 1303,\n 'meticulous': 6350,\n 'filing': 4072,\n 'paperwork': 7190,\n 'state': 9436,\n 'required': 8321,\n 'submitted': 9616,\n 'meanwhile': 6275,\n 'phoned': 7363,\n 'amaz0n': 891,\n 'lodge': 5988,\n 'formal': 4273,\n 'complaint': 2291,\n 'product': 7718,\n 'average': 1224,\n 'worse': 11175,\n 'definitely': 2869,\n 'worth': 11178,\n 'first': 4122,\n 'subwoofer': 9633,\n 'died': 3032,\n 'sound': 9267,\n '6': 389,\n 'days': 2785,\n 'remember': 8238,\n 'sub': 9608,\n 'powers': 7596,\n 'speakers': 9303,\n 'system': 9805,\n 'company': 2256,\n 'nice': 6754,\n 'enough': 3631,\n 'care': 1853,\n 'klipsch': 5669,\n 'faulty': 4002,\n 'asked': 1102,\n 'refund': 8162,\n 'idiot': 5084,\n 'replacement': 8286,\n 'arrived': 1076,\n 'played': 7465,\n '14': 84,\n 'nothing': 6817,\n 'klipsh': 5671,\n 'way': 10958,\n 'designing': 2955,\n 'things': 10022,\n 'past': 7236,\n 'shame': 8906,\n 'making': 6148,\n 'shoddy': 8948,\n 'burned': 1718,\n 'heed': 4834,\n 'warnings': 10915,\n 'friends': 4347,\n 'garage': 4446,\n 'sale': 8620,\n 'warned': 10913,\n 'picture': 7392,\n 'shows': 8987,\n 'cassette': 1894,\n 'feature': 4020,\n 'along': 863,\n 'car': 1845,\n 'kit': 5664,\n 'disappointed': 3098,\n 'perhaps': 7319,\n 'lease': 5821,\n 'durable': 3369,\n '40': 292,\n 'years': 11260,\n 'lights': 5908,\n 'reassuring': 8029,\n 'led': 5831,\n 'gold': 4559,\n 'refuses': 8170,\n 'anything': 988,\n 'xd': 11230,\n 'card': 1848,\n 'worked': 11160,\n '4': 291,\n 'erased': 3685,\n '100': 16,\n 'photos': 7374,\n 'irreplaceable': 5478,\n 'yes': 11262,\n 'junk': 5596,\n 'due': 3352,\n 'construction': 2425,\n 'massage': 6223,\n 'play': 7460,\n 'total': 10169,\n 'waste': 10939,\n 'try': 10338,\n 'give': 4527,\n 'jan': 5526,\n '2006': 167,\n 'md7001': 6264,\n 'line': 5927,\n 'thought': 10040,\n 'cordless': 2520,\n 'actually': 664,\n 'handset': 4731,\n 'requires': 8324,\n 'base': 1309,\n 'unit': 10518,\n 'info': 5267,\n 'prominently': 7752,\n 'displayed': 3156,\n 'description': 2942,\n 'excited': 3795,\n 'headphones': 4806,\n 'creative': 2624,\n 'usually': 10655,\n 'sadly': 8612,\n 'connector': 2391,\n 'clunky': 2155,\n 'surely': 9724,\n 'going': 4558,\n 'wear': 10970,\n 'flimsy': 4187,\n 'wire': 11098,\n 'jack': 5518,\n 'walk': 10878,\n 'street': 9545,\n 'begins': 1385,\n 'distort': 3176,\n 'crazy': 2615,\n 'also': 874,\n 'distorts': 3179,\n 'high': 4873,\n 'volumes': 10837,\n 'need': 6694,\n 'anyway': 991,\n 'runs': 8580,\n 'short': 8960,\n 'worst': 11177,\n 'impossibly': 5159,\n 'tight': 10084,\n 'causing': 1916,\n 'real': 8007,\n 'discomfort': 3114,\n 'using': 10650,\n 'takes': 9853,\n 'aaa': 549,\n 'experience': 3846,\n 'quick': 7895,\n 'units': 10520,\n 'owned': 7113,\n 'lower': 6058,\n 'drain': 3284,\n 'lcd': 5803,\n 'display': 3155,\n 'poor': 7526,\n 'contrast': 2466,\n 'costs': 2549,\n 'bucks': 1682,\n 'installed': 5322,\n 'board': 1526,\n 'pc': 7267,\n 'running': 8579,\n 'xp': 11238,\n 'pro': 7690,\n 'boot': 1569,\n 'tested': 9973,\n 'pci': 7271,\n 'slots': 9138,\n 'cards': 1851,\n 'mixed': 6466,\n 'boots': 1572,\n 'returned': 8417,\n 'removed': 8255,\n 'alone': 862,\n 'speechless': 9322,\n 'guess': 4672,\n 'compatable': 2271,\n 'systems': 9807,\n 'set': 8872,\n 'filled': 4074,\n 'additional': 681,\n 'devices': 3002,\n 'well': 11002,\n 'avaya': 1223,\n 'roadwarrior': 8505,\n 'remotely': 8248,\n 'co': 2164,\n 'worker': 11161,\n 'told': 10133,\n 'gn': 4550,\n 'netcom': 6721,\n 'headset': 4810,\n 'figured': 4065,\n 'save': 8666,\n 'money': 6508,\n 'big': 1438,\n 'major': 6141,\n 'laptops': 5757,\n 'cord': 2517,\n 'plugged': 7490,\n 'listener': 5951,\n 'end': 3593,\n 'sounds': 9276,\n 'airplane': 805,\n 'flight': 4184,\n 'humming': 5028,\n 'goes': 4556,\n 'unplug': 10544,\n 'help': 4845,\n 'able': 563,\n 'chatted': 2007,\n 'plantronics': 7450,\n 'informed': 5270,\n 'known': 5686,\n 'issue': 5500,\n 'around': 1069,\n 'except': 3781,\n 'player': 7466,\n 'ago': 784,\n 'mainly': 6135,\n 'ability': 560,\n 'upgrade': 10599,\n 'firmware': 4119,\n 'region': 8177,\n 'free': 4319,\n 'everything': 3754,\n 'started': 9432,\n 'intermittent': 5388,\n 'graphics': 4608,\n 'staticy': 9441,\n 'blocky': 1507,\n 'buzz': 1747,\n 'eject': 3505,\n 'discs': 3136,\n 'shut': 8992,\n 'restarted': 8377,\n 'lasted': 5767,\n 'became': 1355,\n 'permanent': 7325,\n 'doorstop': 3241,\n 'apex': 1002,\n 'web': 10975,\n 'site': 9064,\n 'appears': 1017,\n 'right': 8470,\n 'based': 1310,\n 'reviews': 8440,\n 'doubt': 3255,\n 'much': 6597,\n 'contacting': 2437,\n 'adore': 720,\n 'nano': 6653,\n 'armband': 1063,\n 'ever': 3746,\n 'bit': 1463,\n 'band': 1293,\n 'comes': 2222,\n 'multiple': 6606,\n 'workout': 11166,\n 'spacing': 9291,\n 'velcro': 10727,\n 'dots': 3250,\n 'exactly': 3768,\n 'fit': 4126,\n 'gets': 4500,\n 'ripped': 8485,\n 'anytime': 989,\n 'weight': 10995,\n 'lifting': 5899,\n 'close': 2137,\n 'body': 1533,\n 'mentioned': 6315,\n 'hugely': 5018,\n 'overpriced': 7098,\n 'ordering': 7012,\n 'different': 3038,\n 'go': 4551,\n 'straight': 9522,\n 'garbage': 4447,\n 'weeks': 10989,\n 'always': 888,\n 'static': 9440,\n 'later': 5777,\n 'went': 11004,\n 'hold': 4919,\n 'workouts': 11167,\n 'barely': 1305,\n 'fits': 4128,\n 'arm': 1062,\n 'tends': 9956,\n 'slide': 9115,\n 'cross': 2650,\n 'training': 10216,\n 'looking': 6019,\n 'break': 1619,\n '20': 159,\n 'minutes': 6432,\n 'ears': 3440,\n 'hurt': 5041,\n 'bad': 1280,\n 'im': 5116,\n 'sure': 9723,\n 'made': 6114,\n 'probably': 7694,\n 'best': 1423,\n 'old': 6943,\n 'several': 8885,\n 'packs': 7141,\n 'discharge': 3109,\n 'without': 11113,\n 'device': 3001,\n 'sell': 8811,\n 'every': 3749,\n 'dollar': 3224,\n 'store': 9512,\n 'quality': 7881,\n 'might': 6384,\n 'loss': 6038,\n 'whatever': 11016,\n 'hook': 4944,\n '50': 342,\n 'stores': 9514,\n 'penny': 7296,\n 'pric': 7662,\n 'states': 9439,\n 'technical': 9915,\n 'details': 2978,\n '450': 314,\n 'pictures': 7395,\n 'cartridge': 1883,\n 'true': 10328,\n 'discussion': 3137,\n 'hp': 4993,\n 'finally': 4087,\n 'admitted': 712,\n 'rated': 7965,\n '150': 92,\n 'x': 11220,\n 'buying': 1744,\n 'printer': 7677,\n 'lot': 6042,\n 'expensive': 3844,\n 'ink': 5288,\n 'returning': 8418,\n 'retract': 8405,\n 'fully': 4376,\n 'mad': 6112,\n 'threw': 10051,\n 'wall': 10886,\n 'defect': 2858,\n 'realized': 8014,\n 'design': 2951,\n 'flaw': 4163,\n 'targus': 9886,\n 'keep': 5621,\n 'receipt': 8052,\n 'guarantee': 4666,\n 'guts': 4686,\n 'release': 8211,\n 'satisfaction': 8653,\n 'guaranteed': 4667,\n 'joke': 5568,\n 'consolidating': 2419,\n 'remote': 8247,\n 'controls': 2475,\n 'regularly': 8190,\n 'plus': 7493,\n 'fan': 3964,\n 'light': 5900,\n 'harmony': 4769,\n '890': 497,\n 'proved': 7796,\n 'disappointment': 3100,\n 'remotes': 8249,\n 'simpler': 9038,\n 'fooling': 4246,\n 'key': 5632,\n 'presses': 7645,\n 'basic': 1314,\n 'functions': 4384,\n 'control': 2471,\n 'programming': 7739,\n 'properly': 7771,\n 'case': 1887,\n 'easier': 3446,\n 'juggle': 5584,\n 'press': 7643,\n 'button': 1737,\n 'sit': 9063,\n 'stick': 9482,\n 'reliabley': 8216,\n 'sony': 9247,\n 'psp': 7810,\n 'current': 2700,\n 'software': 9207,\n 'flawed': 4164,\n 'received': 8056,\n 'defective': 2859,\n 'approximately': 1039,\n '000': 3,\n 'slides': 9118,\n 'scan': 8687,\n '4850': 327,\n 'three': 10049,\n 'four': 4294,\n 'dark': 2765,\n 'blue': 1516,\n 'lines': 5931,\n 'across': 644,\n 'image': 5120,\n 'reporting': 8300,\n 'tma': 10120,\n 'bingo': 1454,\n 'think': 10023,\n 'machine': 6104,\n 'engineered': 3612,\n 'handle': 4725,\n 'load': 5970,\n 'transmitter': 10245,\n 'doesnt': 3220,\n 'recommendations': 8099,\n 'zen': 11283,\n 'daughter': 2778,\n 'saving': 8670,\n 'mp3': 6574,\n 'seem': 8791,\n 'plug': 7488,\n '12': 60,\n 'charging': 1998,\n 'done': 3232,\n 'less': 5857,\n 'may': 6251,\n 'cost': 2541,\n 'exchange': 3792,\n 'eating': 3455,\n 'h': 4692,\n 'read': 7997,\n 'seen': 8795,\n 'pay': 7257,\n 'hate': 4781,\n 'contraption': 2464,\n 'stupidly': 9591,\n 'let': 5863,\n '30': 237,\n 'pass': 7222,\n 'morning': 6532,\n 'boy': 1604,\n 'thing': 10020,\n 'reasons': 8027,\n 'numbers': 6852,\n 'unless': 10524,\n 'within': 11112,\n 'backlight': 1264,\n 'must': 6621,\n 'depress': 2931,\n 'idea': 5075,\n 'horribly': 4965,\n 'executed': 3804,\n 'lasts': 5771,\n 'seconds': 8776,\n 'fast': 3987,\n 'night': 6761,\n 'lie': 5886,\n 'stop': 9504,\n 'radio': 7928,\n 'cd': 1922,\n 'starting': 9433,\n 'whole': 11043,\n 'process': 7707,\n 'figure': 4064,\n 'terminate': 9962,\n 'spends': 9335,\n 'reading': 8002,\n 'playing': 7468,\n 'tuner': 10357,\n 'sensitive': 8834,\n 'lord': 6033,\n 'knows': 5687,\n 'wake': 10874,\n 'screech': 8728,\n 'tuned': 10354,\n 'station': 9443,\n 'happens': 4747,\n 'often': 6933,\n 'called': 1792,\n 'eton': 3730,\n 'tell': 9937,\n 'hated': 4782,\n 'want': 10897,\n 'friendly': 4346,\n 'conversation': 2482,\n 'receptionist': 8065,\n 'assured': 1129,\n 'wanted': 10898,\n 'happy': 4751,\n 'something': 9235,\n 'talk': 9857,\n 'engineer': 3611,\n 'designer': 2954,\n 'waited': 10870,\n 'week': 10984,\n 'rude': 8560,\n 'saying': 8676,\n 'wrong': 11208,\n 'count': 2556,\n 'offered': 6918,\n 'trade': 10206,\n 'mine': 6408,\n 'bother': 1585,\n 'classic': 2091,\n 'story': 9519,\n 'definition': 2870,\n 'errors': 3695,\n 'thrilled': 10052,\n 'brilliant': 1644,\n 'waiting': 10871,\n 'skypephone': 9100,\n 'competitor': 2285,\n 'belkin': 1401,\n 'market': 6207,\n 'numerous': 6854,\n 'postponements': 7571,\n 'gave': 4459,\n 'asus': 1137,\n 'p525': 7126,\n 'smartphone': 9159,\n 'double': 3251,\n 'netgear': 6722,\n 'ce': 1928,\n 'pda': 7276,\n 'gsm': 4660,\n 'capability': 1833,\n 'skype': 9099,\n 'compatibility': 2272,\n 'browsing': 1668,\n 'contacts': 2438,\n 'given': 4529,\n 'choice': 2045,\n 'built': 1697,\n 'wi': 11047,\n 'fi': 4051,\n 'calls': 1796,\n 'chats': 2006,\n 'covered': 2577,\n 'area': 1055,\n 'internet': 5394,\n 'ie': 5089,\n 'check': 2020,\n 'e': 3405,\n 'mails': 6132,\n 'outlook': 7053,\n 'dedicated': 2842,\n 'crude': 2663,\n 'lack': 5718,\n 'processing': 7708,\n 'whereas': 11026,\n 'faster': 3988,\n 'processors': 7710,\n 'allow': 852,\n 'closer': 2140,\n 'pcs': 7274,\n 'alergic': 833,\n 'wait': 10869,\n 'symbian': 9791,\n 'nokia': 6780,\n 'sonyericsson': 9248,\n 'bottom': 1591,\n 'application': 1022,\n 'wasted': 10940,\n 'poorly': 7527,\n 'designed': 2953,\n 'broke': 1656,\n 'see': 8787,\n 'listen': 5948,\n 'us': 10627,\n 'connection': 2388,\n 'browser': 1665,\n 'ask': 1101,\n 'question': 7890,\n 'review': 8434,\n 'speaker': 9301,\n 'look': 6015,\n 'cool': 2500,\n 'stay': 9451,\n 'monster': 6520,\n 'bose': 1582,\n 'word': 11153,\n 'selling': 8815,\n 'cable': 1768,\n 'samsung': 8633,\n 'tv': 10375,\n 'august': 1194,\n 'delivered': 2895,\n 'september': 8850,\n 'opened': 6972,\n 'sunday': 9679,\n 'watched': 10943,\n 'monday': 6506,\n 'lamp': 5735,\n 'fix': 4133,\n 'came': 1800,\n 'football': 4249,\n 'season': 8766,\n 'decided': 2830,\n 'replace': 8283,\n 'giving': 4531,\n 'runaround': 8575,\n 'blaming': 1474,\n 'shipping': 8942,\n 'warehouse': 10907,\n 'etc': 3727,\n 'delay': 2883,\n 'sending': 8822,\n 'basically': 1315,\n 'far': 3976,\n 'behind': 1391,\n 'ship': 8938,\n 'lots': 6043,\n 'took': 10148,\n 'loved': 6053,\n 'developed': 2997,\n 'loud': 6044,\n 'noise': 6777,\n 'makes': 6147,\n 'music': 6615,\n 'disapointed': 3092,\n 'wish': 11106,\n 'someone': 9232,\n 'posted': 7569,\n 'dec': 2821,\n '22': 183,\n 'posting': 7570,\n 'excellent': 3780,\n 'pointing': 7511,\n 'ipod': 5461,\n 'shuffle': 8990,\n 'spent': 9336,\n 'stuck': 9579,\n 'rats': 7975,\n 'compatible': 2275,\n 'ipods': 5462,\n 'evidently': 3761,\n 'difference': 3036,\n 'recent': 8061,\n 'itrip': 5512,\n 'fall': 3952,\n 'apart': 997,\n 'wood': 11145,\n 'veneer': 10731,\n 'pulled': 7827,\n 'splintered': 9352,\n 'tightening': 10088,\n 'strings': 9563,\n 'tune': 10349,\n 'guitar': 4679,\n 'incompatibility': 5204,\n 'screen': 8729,\n 'showed': 8983,\n 'voice': 10820,\n 'recorder': 8111,\n 'record': 8108,\n 'error': 3694,\n 'locate': 5977,\n 'microphone': 6367,\n '4th': 338,\n 'generation': 4477,\n 'gig': 4510,\n 'updated': 10596,\n 'needs': 6698,\n 'recorders': 8112,\n 'exception': 3783,\n 'minis': 6420,\n 'resolve': 8354,\n 'throw': 10059,\n 'ball': 1290,\n 'agree': 786,\n 'previous': 7659,\n 'retracts': 8410,\n 'keeps': 5624,\n 'responsibility': 8370,\n 'seller': 8813,\n 'sorry': 9261,\n 'horrible': 4964,\n 'enjoyment': 3628,\n 'crap': 2604,\n 'bathroom': 1324,\n 'connects': 2393,\n 'pocket': 7499,\n 'palm': 7165,\n 'mistakenly': 6462,\n 'order': 7010,\n 'com': 2211,\n 'day': 2783,\n 'portable': 7541,\n 'gps': 4579,\n 'travels': 10265,\n 'eight': 3499,\n 'upgrading': 10602,\n '1600mah': 103,\n 'rayovac': 7983,\n 'nimh': 6767,\n 'aa': 548,\n 'strong': 9567,\n 'saw': 8673,\n 'energizer': 3603,\n '2500mah': 200,\n 'rechargeables': 8071,\n 'thinking': 10024,\n 'rayovacs': 7984,\n 'energizers': 3604,\n '7': 428,\n 'roughly': 8535,\n 'spec': 9306,\n 'ed': 3468,\n 'pair': 7162,\n 'seemed': 8792,\n 'flawlessly': 4166,\n 'okay': 6942,\n 'appearing': 1016,\n '5th': 386,\n 'initial': 5281,\n 'lucky': 6077,\n 'trusty': 10334,\n 'combinations': 2215,\n 'decent': 2827,\n 'charges': 1997,\n 'disappointing': 3099,\n 'brand': 1613,\n 'capacity': 1836,\n 'zboard': 11281,\n 'sorely': 9259,\n 'playbility': 7463,\n 'efficiency': 3490,\n 'value': 10695,\n 'mirroring': 6435,\n 'lag': 5726,\n 'interpret': 5396,\n 'program': 7733,\n 'game': 4435,\n 'personally': 7340,\n 'command': 2232,\n 'register': 8179,\n 'configured': 2366,\n 'configure': 2365,\n 'templates': 9946,\n 'games': 4442,\n 'modified': 6489,\n 'change': 1979,\n 'configuration': 2362,\n 'patches': 7241,\n 'configuring': 2367,\n 'keys': 5640,\n 'according': 615,\n 'top': 10154,\n 'media': 6285,\n 'winamp': 11072,\n 'itunes': 5513,\n 'else': 3536,\n 'macros': 6110,\n 'autofire': 1205,\n 'keystrokes': 5642,\n 'numpad': 6855,\n 'differently': 3042,\n 'normal': 6798,\n 'compacted': 2250,\n 'pad': 7142,\n 'found': 4293,\n 'frustrating': 4359,\n 'attack': 1160,\n 'commands': 2233,\n 'sometimes': 9238,\n 'layout': 5797,\n ...}"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# print(allData[0:2])\n",
    "bow_converter = CountVectorizer(tokenizer=lambda doc: doc)\n",
    "y = bow_converter.fit_transform(df['Text_Cleaned'])\n",
    "# bigram_converter = CountVectorizer(tokenizer=lambda doc: doc, ngram_range=[2,2])\n",
    "# tfidf_transform = text.TfidfTransformer(norm=None)\n",
    "# X_tfidf = tfidf_transform.fit_transform(X_bow)\n",
    "bow_converter.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def simple_logistic_classify(trainingData, trainingLabels, testingData, testingLabels, description, _C=1.0):\n",
    "    model = LogisticRegression(C=_C).fit(trainingData, trainingLabels)\n",
    "    score = model.score(testingData, testingLabels)\n",
    "    print('Test Score with', description, 'features', score)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingLabels: [0 0 0 ... 1 1 1]\n",
      "  (0, 52)\t15\n",
      "  (0, 55)\t5\n",
      "  (0, 41)\t6\n",
      "  (0, 42)\t16\n",
      "  (0, 3)\t30\n",
      "  (0, 43)\t2\n",
      "  (0, 50)\t4\n",
      "  (0, 62)\t3\n",
      "  (0, 45)\t10\n",
      "  (0, 53)\t2\n",
      "  (0, 23)\t1\n",
      "  (0, 26)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 24)\t1\n",
      "  (0, 17)\t3\n",
      "  (0, 57)\t16\n",
      "  (0, 46)\t6\n",
      "  (0, 56)\t5\n",
      "  (0, 51)\t7\n",
      "  (0, 38)\t6\n",
      "  (0, 39)\t5\n",
      "  (0, 49)\t2\n",
      "  (0, 58)\t2\n",
      "  (0, 48)\t2\n",
      "  (0, 60)\t2\n",
      "  :\t:\n",
      "  (1599, 3)\t27\n",
      "  (1599, 43)\t2\n",
      "  (1599, 50)\t1\n",
      "  (1599, 62)\t2\n",
      "  (1599, 45)\t5\n",
      "  (1599, 53)\t6\n",
      "  (1599, 26)\t1\n",
      "  (1599, 19)\t2\n",
      "  (1599, 17)\t1\n",
      "  (1599, 57)\t6\n",
      "  (1599, 46)\t5\n",
      "  (1599, 56)\t5\n",
      "  (1599, 51)\t5\n",
      "  (1599, 38)\t6\n",
      "  (1599, 39)\t2\n",
      "  (1599, 49)\t3\n",
      "  (1599, 58)\t5\n",
      "  (1599, 60)\t1\n",
      "  (1599, 16)\t5\n",
      "  (1599, 59)\t2\n",
      "  (1599, 40)\t3\n",
      "  (1599, 44)\t2\n",
      "  (1599, 1)\t1\n",
      "  (1599, 61)\t1\n",
      "  (1599, 27)\t1\n",
      "  (0, 44)\t30\n",
      "  (0, 2)\t96\n",
      "  (0, 45)\t1\n",
      "  (0, 56)\t14\n",
      "  (0, 54)\t33\n",
      "  (0, 55)\t44\n",
      "  (0, 51)\t10\n",
      "  (0, 53)\t22\n",
      "  (0, 38)\t9\n",
      "  (0, 43)\t17\n",
      "  (0, 36)\t35\n",
      "  (0, 40)\t41\n",
      "  (0, 39)\t11\n",
      "  (0, 48)\t9\n",
      "  (0, 50)\t36\n",
      "  (0, 16)\t6\n",
      "  (0, 42)\t7\n",
      "  (0, 41)\t8\n",
      "  (0, 47)\t16\n",
      "  (0, 49)\t18\n",
      "  (0, 60)\t11\n",
      "  (0, 58)\t7\n",
      "  (0, 46)\t3\n",
      "  (0, 14)\t4\n",
      "  (0, 37)\t5\n",
      "  :\t:\n",
      "  (399, 48)\t15\n",
      "  (399, 50)\t38\n",
      "  (399, 16)\t5\n",
      "  (399, 42)\t12\n",
      "  (399, 41)\t8\n",
      "  (399, 47)\t24\n",
      "  (399, 49)\t38\n",
      "  (399, 60)\t11\n",
      "  (399, 58)\t12\n",
      "  (399, 14)\t3\n",
      "  (399, 37)\t8\n",
      "  (399, 15)\t1\n",
      "  (399, 57)\t7\n",
      "  (399, 19)\t2\n",
      "  (399, 26)\t1\n",
      "  (399, 10)\t2\n",
      "  (399, 11)\t2\n",
      "  (399, 1)\t1\n",
      "  (399, 9)\t2\n",
      "  (399, 52)\t2\n",
      "  (399, 18)\t4\n",
      "  (399, 23)\t2\n",
      "  (399, 24)\t1\n",
      "  (399, 6)\t1\n",
      "  (399, 25)\t1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylanedwards/Desktop/oxy-nlp/hw2/venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 63 features, but LogisticRegression is expecting 68 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zz/yhmtwxfj489c3r52w8d8rqnr0000gn/T/ipykernel_14102/1055797353.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     27\u001B[0m     \u001B[0;31m# score = model.score(testingData, testingLabels)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[0;31m#\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 29\u001B[0;31m     \u001B[0mlabelPrediction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict_proba\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtestingData\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     30\u001B[0m     \u001B[0;31m# print(\"label pred\", labelPrediction)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/oxy-nlp/hw2/venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001B[0m in \u001B[0;36mpredict_proba\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m   1668\u001B[0m         )\n\u001B[1;32m   1669\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0movr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1670\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_predict_proba_lr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1671\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1672\u001B[0m             \u001B[0mdecision\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecision_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/oxy-nlp/hw2/venv/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001B[0m in \u001B[0;36m_predict_proba_lr\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    437\u001B[0m         \u001B[0mmulticlass\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mhandled\u001B[0m \u001B[0mby\u001B[0m \u001B[0mnormalizing\u001B[0m \u001B[0mthat\u001B[0m \u001B[0mover\u001B[0m \u001B[0mall\u001B[0m \u001B[0mclasses\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    438\u001B[0m         \"\"\"\n\u001B[0;32m--> 439\u001B[0;31m         \u001B[0mprob\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecision_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    440\u001B[0m         \u001B[0mexpit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprob\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mprob\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    441\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mprob\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/oxy-nlp/hw2/venv/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001B[0m in \u001B[0;36mdecision_function\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    405\u001B[0m         \u001B[0mcheck_is_fitted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    406\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 407\u001B[0;31m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"csr\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    408\u001B[0m         \u001B[0mscores\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msafe_sparse_dot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcoef_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdense_output\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mintercept_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    409\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/oxy-nlp/hw2/venv/lib/python3.8/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    574\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    575\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mcheck_params\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"ensure_2d\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 576\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_n_features\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    577\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    578\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/oxy-nlp/hw2/venv/lib/python3.8/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m_check_n_features\u001B[0;34m(self, X, reset)\u001B[0m\n\u001B[1;32m    393\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    394\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mn_features\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_features_in_\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 395\u001B[0;31m             raise ValueError(\n\u001B[0m\u001B[1;32m    396\u001B[0m                 \u001B[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    397\u001B[0m                 \u001B[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: X has 63 features, but LogisticRegression is expecting 68 features as input."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "#Unsupervised smooth-inverse frequency (uSIF) weighted sentence embeddings model.\n",
    "\n",
    "\n",
    "for trainingIndex, testingIndex in kf.split(allData):\n",
    "    trainingData, testingData = allData[trainingIndex], allData[testingIndex]\n",
    "    trainingLabels, testingLabels = allLabels[trainingIndex], allLabels[testingIndex]\n",
    "\n",
    "    print(\"trainingLabels:\", trainingLabels)\n",
    "    # train naive bayes model\n",
    "    # gnb = GaussianNB()\n",
    "    # gnb.fit(train_embed, trainingLabels)\n",
    "    bow_converter = CountVectorizer(tokenizer=lambda doc: doc)\n",
    "    trainingData = bow_converter.fit_transform(trainingData)\n",
    "    testingData = bow_converter.fit_transform(testingData)\n",
    "    print(trainingData)\n",
    "    print(testingData)\n",
    "    model = LogisticRegression(C=1.0).fit(trainingData, trainingLabels)\n",
    "\n",
    "    # score = model.score(testingData, testingLabels)\n",
    "    #\n",
    "    labelPrediction = model.predict_proba(testingData)[:, 1]\n",
    "    # print(\"label pred\", labelPrediction)\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(testingLabels, labelPrediction)\n",
    "    average_precision = average_precision_score(testingLabels, labelPrediction)\n",
    "\n",
    "    disp = plot_precision_recall_curve(model, testingData, testingLabels)\n",
    "    disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                       'AP={0:0.2f}'.format(average_precision))\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# print(allData[0:2])\n",
    "# bow_converter = CountVectorizer(tokenizer=lambda doc: doc)\n",
    "# y = bow_converter.fit_transform(allData[0:2])\n",
    "# # bigram_converter = CountVectorizer(tokenizer=lambda doc: doc, ngram_range=[2,2])\n",
    "# # tfidf_transform = text.TfidfTransformer(norm=None)\n",
    "# # X_tfidf = tfidf_transform.fit_transform(X_bow)\n",
    "# print(bow_converter.get_stop_words())\n",
    "# words = bow_converter.get_feature_names()\n",
    "# print(len(words))\n",
    "# print(words)\n",
    "# print(len(bow_converter.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}